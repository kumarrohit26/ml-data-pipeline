# ml-data-pipeline

This repo will produce and consume data to and from kafka confluent in json format

Step 1: Create a conda environment
```
conda create -p venv python==3.8 -y
```

Step 2: Activate conda environment
```
conda activate venv/
```

Step 3: Install required packages
```
pip install -r requirements.txt
```

Create a free account on confluent.
- Create environment
- Create api keys
- Create topic
- Create Stream Governance API
- Create Stream Governance Credentials